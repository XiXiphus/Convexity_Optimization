\documentclass[10pt]{extarticle}
\usepackage{utils}

\addbibresource{bibliography}

\title{\huge\bfseries Exercise For Convexity and Optimization in $\mathbb{R}^n$}
\author{\Large Qiuyi Chen\\
Qiuyi.Chen@liverpool.ac.uk}

\date{\calligra{May, 2025}}

\begin{document}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}
\maketitle

\begin{tcolorbox}[title=Contents, fonttitle=\huge\sffamily\bfseries\selectfont,interior style={left color=contcol1!40!white,right color=contcol2!40!white},frame style={left color=contcol1!80!white,right color=contcol2!80!white},coltitle=black,top=2mm,bottom=2mm,left=2mm,right=2mm,drop fuzzy shadow,enhanced,breakable]
    \makeatletter
    \@starttoc{toc}
    \makeatother
\end{tcolorbox}

\vspace*{10mm}

\clearpage
\vspace*{\fill}
\begin{center}
    Dedicated to the knee scrapes, playdates, and heartaches.
\end{center}

\vspace*{\fill}
\clearpage
\section{Topics in Real Analysis}
\subsection{Introduction}
\begin{exercise}[1.1]
    For any vectors $\bf{x}$ and $\bf{y}$ in $\mathbb{R}^n$, show that ${\Vert \bf{x} + \bf{y} \Vert}^2 +{\Vert \bf{x} - \bf{y} \Vert}^2 = 2{\Vert \bf{x} \Vert}^2 + 2{\Vert \bf{y} \Vert}^2$. Interpret this relation as a statement about parallelograms in $\mathbb{R}^2$ and $\mathbb{R}^3$.
\end{exercise}

\begin{solution}
    To prove that $\Vert\mathbf{x} + \mathbf{y}\Vert^2 + \Vert\mathbf{x} - \mathbf{y}\Vert^2 = 2\Vert\mathbf{x}\Vert^2 + 2\Vert\mathbf{y}\Vert^2$ for any vectors $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$, we use the definition of the Euclidean norm and properties of the dot product. Recall that $\Vert\mathbf{x}\Vert^2 = \mathbf{x} \cdot \mathbf{x}$.

    First, expand $\Vert\mathbf{x} + \mathbf{y}\Vert^2$:
    $$
        \Vert\mathbf{x} + \mathbf{y}\Vert^2 = (\mathbf{x} + \mathbf{y}) \cdot (\mathbf{x} + \mathbf{y}) = \mathbf{x} \cdot \mathbf{x} + 2\mathbf{x} \cdot \mathbf{y} + \mathbf{y} \cdot \mathbf{y} = \Vert\mathbf{x}\Vert^2 + 2(\mathbf{x} \cdot \mathbf{y}) + \Vert\mathbf{y}\Vert^2.
    $$

    Next, expand $\Vert\mathbf{x} - \mathbf{y}\Vert^2$:
    $$
        \Vert\mathbf{x} - \mathbf{y}\Vert^2 = (\mathbf{x} - \mathbf{y}) \cdot (\mathbf{x} - \mathbf{y}) = \mathbf{x} \cdot \mathbf{x} - 2\mathbf{x} \cdot \mathbf{y} + \mathbf{y} \cdot \mathbf{y} = \Vert\mathbf{x}\Vert^2 - 2(\mathbf{x} \cdot \mathbf{y}) + \Vert\mathbf{y}\Vert^2.
    $$

    Add these two expressions:
    $$
        \Vert\mathbf{x} + \mathbf{y}\Vert^2 + \Vert\mathbf{x} - \mathbf{y}\Vert^2 = \left( \Vert\mathbf{x}\Vert^2 + 2(\mathbf{x} \cdot \mathbf{y}) + \Vert\mathbf{y}\Vert^2 \right) + \left( \Vert\mathbf{x}\Vert^2 - 2(\mathbf{x} \cdot \mathbf{y}) + \Vert\mathbf{y}\Vert^2 \right) = \Vert\mathbf{x}\Vert^2 + \Vert\mathbf{x}\Vert^2 + \Vert\mathbf{y}\Vert^2 + \Vert\mathbf{y}\Vert^2 + 2(\mathbf{x} \cdot \mathbf{y}) - 2(\mathbf{x} \cdot \mathbf{y}).
    $$

    The cross terms $2(\mathbf{x} \cdot \mathbf{y})$ and $-2(\mathbf{x} \cdot \mathbf{y})$ cancel, yielding:
    $$
        \Vert\mathbf{x} + \mathbf{y}\Vert^2 + \Vert\mathbf{x} - \mathbf{y}\Vert^2 = 2\Vert\mathbf{x}\Vert^2 + 2\Vert\mathbf{y}\Vert^2.
    $$

    Thus, the equality holds for all $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$.

    \medskip

    In $\mathbb{R}^2$ and $\mathbb{R}^3$, this equality has a geometric interpretation related to parallelograms. Consider vectors $\mathbf{x}$ and $\mathbf{y}$ emanating from the same initial point. These vectors form two adjacent sides of a parallelogram. The vector $\mathbf{x} + \mathbf{y}$ represents one diagonal of the parallelogram, and $\mathbf{x} - \mathbf{y}$ represents the other diagonal (assuming the parallelogram is completed appropriately).

    The left side of the equality, $\Vert\mathbf{x} + \mathbf{y}\Vert^2 + \Vert\mathbf{x} - \mathbf{y}\Vert^2$, is the sum of the squares of the lengths of the two diagonals. The right side, $2\Vert\mathbf{x}\Vert^2 + 2\Vert\mathbf{y}\Vert^2$, is twice the sum of the squares of the lengths of the two adjacent sides. Since a parallelogram has two pairs of equal sides, the sum of the squares of the lengths of all four sides is $2\Vert\mathbf{x}\Vert^2 + 2\Vert\mathbf{y}\Vert^2$ (two sides of length $\Vert\mathbf{x}\Vert$ and two of length $\Vert\mathbf{y}\Vert$).

    Therefore, the equality states that for any parallelogram in $\mathbb{R}^2$ or $\mathbb{R}^3$, the sum of the squares of the lengths of the diagonals equals the sum of the squares of the lengths of all four sides. This is a fundamental property of parallelograms in Euclidean geometry, often called the parallelogram law.
\end{solution}

\setcounter{subsection}{2}
\subsection{Algebra of Sets}

\begin{lemma}[3.1]
    Let $\left\{S_\alpha\right\}_{\alpha \in A}$ be a collection of subsets of a set $X$. Then

    \begin{equation*}
        \begin{aligned}
             & \bigcup_{\alpha \in A} S_\alpha=c\left[\bigcap_{\alpha \in A}\left(c S_\alpha\right)\right],  \\
             & \bigcap_{\alpha \in A} S_\alpha=c\left[\bigcup_{\alpha \in A}\left(c S_\alpha\right)\right] .
        \end{aligned}
    \end{equation*}

\end{lemma}
\begin{proof}
    We establish both identities by showing mutual inclusion of the corresponding sets.

    \medskip
    \textbf{1.~$\displaystyle \bigcup_{\alpha\in A} S_{\alpha} \;=\; c\Bigl[\bigcap_{\alpha\in A} (c S_{\alpha})\Bigr]$.}

    \emph{(i)~Subset relation $\subseteq$.}  Let $x \in \bigcup_{\alpha\in A} S_{\alpha}$.  Then there exists an index $\alpha_0 \in A$ such that $x \in S_{\alpha_0}$.  If $x$ were also contained in $\bigcap_{\alpha\in A} (c S_{\alpha})$, it would belong to $c S_{\alpha_0}$, i.e.~$x \notin S_{\alpha_0}$, a contradiction.  Therefore $x \notin \bigcap_{\alpha\in A} (c S_{\alpha})$, which means $x \in c\bigl[\bigcap_{\alpha\in A} (c S_{\alpha})\bigr]$.

    \emph{(ii)~Subset relation $\supseteq$.}  Conversely, take $x \in c\bigl[\bigcap_{\alpha\in A} (c S_{\alpha})\bigr]$.  Then $x \notin \bigcap_{\alpha\in A} (c S_{\alpha})$, so there exists an index $\alpha_1 \in A$ with $x \notin c S_{\alpha_1}$.  Equivalently, $x \in S_{\alpha_1}$, hence $x \in \bigcup_{\alpha\in A} S_{\alpha}$.  Combining (i) and (ii) yields the desired equality.

    \medskip
    \textbf{2.~$\displaystyle \bigcap_{\alpha\in A} S_{\alpha} \;=\; c\Bigl[\bigcup_{\alpha\in A} (c S_{\alpha})\Bigr]$.}

    The argument is analogous.

    \emph{(i)~Subset relation $\subseteq$.}  Let $x \in \bigcap_{\alpha\in A} S_{\alpha}$.  Then $x \in S_{\alpha}$ for every $\alpha$.  Consequently, $x \notin c S_{\alpha}$ for any $\alpha$, which implies $x \notin \bigcup_{\alpha\in A} (c S_{\alpha})$.  Hence $x \in c\bigl[\bigcup_{\alpha\in A} (c S_{\alpha})\bigr]$.

    \emph{(ii)~Subset relation $\supseteq$.}  Let $x \in c\bigl[\bigcup_{\alpha\in A} (c S_{\alpha})\bigr]$.  Then $x \notin \bigcup_{\alpha\in A} (c S_{\alpha})$, so for every $\alpha \in A$ we have $x \notin c S_{\alpha}$; equivalently $x \in S_{\alpha}$.  Therefore $x \in \bigcap_{\alpha\in A} S_{\alpha}$.

    Since both inclusions hold, the second identity follows.
\end{proof}

\subsection{Metric Topology of $\mathbb{R}^n$}

\begin{exercise}[4.1]
    Use the properties of the norm to show that the function $d$ defined by
    $$
        d(\mathbf{x}, \mathbf{y}) = \Vert \mathbf{x} - \mathbf{y} \Vert = \left(\sum_{i=1}^{n}(x_i - y_i)^2\right)^{1/2}
    $$
    is a metric, or distance function, on $\mathbb{R}^n$.
\end{exercise}

\begin{proof}
    To verify that $d(\mathbf{x}, \mathbf{y}) = \Vert \mathbf{x} - \mathbf{y} \Vert$ is a metric on $\mathbb{R}^n$, we must show that it satisfies the following three properties for all $\mathbf{x}, \mathbf{y}, \mathbf{z} \in \mathbb{R}^n$:
    \emph{(i)} non--negativity with the identity of indiscernibles, \emph{(ii)} symmetry, and \emph{(iii)} the triangle inequality.

    \medskip
    \textbf{1.~Non--negativity and identity of indiscernibles.} The Euclidean norm is always non--negative, so
    $$
        d(\mathbf{x}, \mathbf{y}) = \Vert \mathbf{x} - \mathbf{y} \Vert \ge 0.
    $$
    Moreover, $d(\mathbf{x}, \mathbf{y}) = 0$ if and only if $\Vert \mathbf{x} - \mathbf{y} \Vert = 0$, which occurs precisely when $\mathbf{x} - \mathbf{y} = \mathbf{0}$, i.e.~when $\mathbf{x} = \mathbf{y}$.

    \medskip
    \textbf{2.~Symmetry.} Because $\Vert \mathbf{v} \Vert = \Vert -\mathbf{v} \Vert$ for any vector $\mathbf{v}$,
    $$
        d(\mathbf{x}, \mathbf{y}) = \Vert \mathbf{x} - \mathbf{y} \Vert = \Vert -(\mathbf{x} - \mathbf{y}) \Vert = \Vert \mathbf{y} - \mathbf{x} \Vert = d(\mathbf{y}, \mathbf{x}).
    $$

    \medskip
    \textbf{3.~Triangle inequality.} The Euclidean norm satisfies the triangle inequality $\Vert \mathbf{u} + \mathbf{v} \Vert \le \Vert \mathbf{u} \Vert + \Vert \mathbf{v} \Vert$. Choosing $\mathbf{u} = \mathbf{x} - \mathbf{y}$ and $\mathbf{v} = \mathbf{y} - \mathbf{z}$ gives
    $$
        d(\mathbf{x}, \mathbf{z}) = \Vert \mathbf{x} - \mathbf{z} \Vert = \Vert (\mathbf{x} - \mathbf{y}) + (\mathbf{y} - \mathbf{z}) \Vert \le \Vert \mathbf{x} - \mathbf{y} \Vert + \Vert \mathbf{y} - \mathbf{z} \Vert = d(\mathbf{x}, \mathbf{y}) + d(\mathbf{y}, \mathbf{z}).
    $$

    Since all three axioms hold, the function $d$ is indeed a metric on $\mathbb{R}^n$.
\end{proof}
\begin{exercise}[4.2]
    (a) Sketch the graph of $y=\sin(1/x)$ for $x>0$.\\
    (b) Consider the graph as a set in $\mathbb{R}^2$ and find the limit points of this set.
\end{exercise}
\begin{solution}
    \textbf{(a)~Sketch of the curve.}  Set $t = 1/x$ for $x>0$.  Then the graph of $y = \sin(1/x)$ for $x>0$ corresponds to the standard sine curve $y = \sin t$ for $t>0$, but viewed through the change of variables $x = 1/t$.  As $x \to 0^{+}$ we have $t \to +\infty$, so the curve oscillates infinitely often between $-1$ and $1$ while its $x$--coordinate approaches~$0$.  For moderate values of~$x$ the graph resembles the usual sine curve stretched horizontally, whereas near the $y$--axis the oscillations become increasingly rapid, creating a "comb-like" fringe that accumulates on the interval $\{0\}\times[-1,1]$.

    \medskip
    \textbf{(b)~Limit points of the graph.}  Let
    $$
        S \;:=\; \bigl\{\,(x,\sin(1/x)) : x>0\,\bigr\}\subset \mathbb{R}^{2}.
    $$
    We claim that the set of limit points of $S$ is
    $$
        S' \;=\; S \;\cup\; \bigl\{\,(0,y) : -1 \le y \le 1\,\bigr\}.
    $$
    The verification proceeds in two steps.

    \medskip
    \emph{Step~1:  Every point of $S$ is a limit point.}  Fix $(x_{0},\sin(1/x_{0})) \in S$ with $x_{0}>0$ and let $\varepsilon>0$ be given.  Recall the elementary inequality $|\sin u-\sin v|\le |u-v|$ valid for all real numbers $u,v$.  Set
    $$
        \delta := \min\Bigl\{\frac{\varepsilon}{2},\, \frac{\varepsilon x_{0}^{2}}{4},\, \frac{x_{0}}{2}\Bigr\}.
    $$
    Pick any $x_{\varepsilon}\in(x_{0}-\delta,x_{0}+\delta)\setminus\{x_{0}\}$ and define $P_{\varepsilon}:=(x_{\varepsilon},\sin(1/x_{\varepsilon}))$.  Then $P_{\varepsilon}\in S$ and
    $$
        |x_{\varepsilon}-x_{0}|<\frac{\varepsilon}{2},\qquad |\sin(1/x_{\varepsilon})-\sin(1/x_{0})|\le |1/x_{\varepsilon}-1/x_{0}|=\frac{|x_{\varepsilon}-x_{0}|}{|x_{\varepsilon}|x_{0}}\le \frac{2\delta}{x_{0}^{2}}\le \frac{\varepsilon}{2}.
    $$
    Consequently
    $$
        \bigl\|P_{\varepsilon}-(x_{0},\sin(1/x_{0}))\bigr\|\le \sqrt{\bigl(|x_{\varepsilon}-x_{0}|\bigr)^{2}+\bigl(|\sin(1/x_{\varepsilon})-\sin(1/x_{0})|\bigr)^{2}}<\varepsilon,
    $$
    proving that $(x_{0},\sin(1/x_{0}))$ is indeed a limit point of $S$.

    \medskip
    \emph{Step~2:  Points of the form $(0,y)$ with $|y|\le 1$ are limit points.}  Fix $y\in[-1,1]$ and $\varepsilon>0$.  Because the sine function attains every value in $[-1,1]$ infinitely often, we can pick $t_{\varepsilon}>\max\{1/\varepsilon,0\}$ such that $|\sin t_{\varepsilon}-y|<\varepsilon$.  Setting $x_{\varepsilon}=1/t_{\varepsilon}$ we obtain $0<x_{\varepsilon}<\varepsilon$ and
    $$
        \bigl\|(x_{\varepsilon},\sin(1/x_{\varepsilon}))-(0,y)\bigr\|<\sqrt{\varepsilon^{2}+\varepsilon^{2}}<\sqrt{2}\,\varepsilon.
    $$
    Thus $(0,y)$ is approached by points of $S$ distinct from itself, so it is a limit point.

    \medskip
    \emph{Step~3:  No other points are limit points.}  If $x<0$, every open ball centred at $(x,y)$ contains points whose first coordinate is negative, whereas $S$ lies entirely in $x>0$; thus such points cannot be limit points.  If $x=0$ but $|y|>1$, the vertical separation $|y|-1$ already exceeds the range of $\sin$, so no sequence in $S$ can approach $(0,y)$.

    Finally, consider a point $(x,y)$ with $x>0$ that does \\emph{not} belong to $S$.  Write $y_{0}:=\sin(1/x)$ and set $d:=|y-y_{0}|>0$.  Choose
    $$
        r:=\min\Bigl\{\frac{d}{2},\,\frac{x}{2}\Bigr\}.
    $$
    For any $(x',\sin(1/x'))\in S$ satisfying $|x'-x|<r$ we have $x'\ge x/2$ and hence, using $|\sin u-\sin v|\le|u-v|$ again,
    $$
        |\sin(1/x')-y_{0}|\le \frac{|x'-x|}{x' x}\le \frac{2r}{x^{2}}\le \frac{d}{2}.
    $$
    Therefore
    $$
        |\sin(1/x')-y|\ge |y-y_{0}|-|\sin(1/x')-y_{0}|>\frac{d}{2},
    $$
    so the Euclidean distance between $(x',\sin(1/x'))$ and $(x,y)$ exceeds $d/2$.  Hence the ball $B\bigl((x,y),d/2\bigr)$ contains no point of $S$, proving that $(x,y)$ is not a limit point.  Collecting the cases established in Steps~1--3 completes the description of $S'$.

    \medskip
    Consequently, the set of all limit points of the graph is precisely $S\cup\bigl(\{0\}\times[-1,1]\bigr)$, as asserted.
\end{solution}

\begin{exercise}[4.3]
    Show that for $x \in \mathbb{R}^n$ and $r>0$ the set $B(x , r)$ is open; that is, show that an open ball is open.
\end{exercise}

\begin{proof}
    Let $y \in B(x,r)$, so by definition $\|y-x\| < r$.  Define
    $$
        \varepsilon \;:=\; r - \|y-x\| \;>\; 0.
    $$
    We claim that the entire ball $B(y,\varepsilon)$ is contained in $B(x,r)$.  Indeed, if $z \in B(y,\varepsilon)$ then $\|z-y\| < \varepsilon$, and by the triangle inequality,
    $$
        \|z-x\| \;\le\; \|z-y\| + \|y-x\| \;<\; \varepsilon + \|y-x\| \;=\; r.
    $$
    Hence $z \in B(x,r)$.  Since every point $y$ of $B(x,r)$ is an interior point, the set $B(x,r)$ is open.
\end{proof}

\begin{remark}
    \emph{Idea of the proof.}  To show that the open ball $B(x,r)$ is an open set we verify that every point it contains is an interior point.  Fix $y\in B(x,r)$ and measure how much "room" is left before reaching the boundary: the gap is $\varepsilon:=r-\|y-x\|>0$.  Any point $z$ that sits within this gap around $y$ (that is, $\|z-y\|<\varepsilon$) cannot escape the larger ball, because the triangle inequality guarantees $\|z-x\|<\|z-y\|+\|y-x\|<\varepsilon+\bigl(r-\varepsilon\bigr)=r$.  Thus the smaller ball $B(y,\varepsilon)$ lies completely inside $B(x,r)$, making $y$ an interior point.  Since $y$ was arbitrary, $B(x,r)$ is open.
\end{remark}

\begin{exercise}[4.4]
    Show that for $x \in \mathbb{R}^n$ and $r>0$ the closed ball $\overline{B(x , r)}$ is closed.
\end{exercise}

\begin{proof}
    Set $C:=\overline{B(x,r)}=\{y\in\mathbb R^{n}:\|y-x\|\le r\}$.  We show that its complement $C^{c}$ is open.  Let $y\in C^{c}$, so $\|y-x\|>r$.  Define
    \[
        \varepsilon\;:=\;\frac{\|y-x\|-r}{2}\;>\;0.
    \]
    If $z\in B(y,\varepsilon)$ then $\|z-y\|<\varepsilon$, and by the triangle inequality,
    \[
        \|z-x\|\;\ge\;\|y-x\|-\|z-y\|\;>\;\bigl(r+2\varepsilon\bigr)-\varepsilon\;=\;r+\varepsilon\;>\;r.
    \]
    Hence $z\notin C$.  Therefore $B(y,\varepsilon)\subset C^{c}$, proving that every point of $C^{c}$ is interior.  The complement of $C$ is open, so $C$ is closed.
\end{proof}

\begin{remark}
    \emph{Idea of the proof.}  For a point $y$ lying \emph{outside} the closed ball we measure how far it is from the boundary: the surplus distance is $\delta:=\|y-x\|-r>0$.  Choosing half of this surplus as a radius, $\varepsilon=\delta/2$, guarantees that the entire ball $B(y,\varepsilon)$ stays outside, because any point inside that small ball remains at least $r+\varepsilon>r$ away from $x$.  Since such a neighbourhood exists around each exterior point, the complement of the closed ball is open, which is exactly the definition of the original set being closed.
\end{remark}

\begin{exercise}[4.5]
    Show that any finite set of points $x _1, \ldots, x _k$ in $\mathbb{R}^n$ is closed.
\end{exercise}

\begin{proof}
    Denote the finite set by $F:=\{x_{1},\ldots,x_{k}\}$.  We show that its complement $F^{c}$ is open.  Let $y\in F^{c}$; then $y\neq x_{i}$ for every $i$.  Define the positive distances
    \[
        d_{i}:=\|y-x_{i}\|>0, \qquad i=1,\ldots,k, \quad\text{and set}\quad \varepsilon:=\tfrac12\min_{1\le i\le k} d_{i}>0.
    \]
    For any $z\in B(y,\varepsilon)$ we have $\|z-y\|<\varepsilon\le d_{i}/2$, hence by the triangle inequality
    \[
        \|z-x_{i}\| \;\ge\; \|y-x_{i}\|-\|z-y\| \;>\; d_{i}-\varepsilon \;\ge\; \tfrac12 d_{i}>0\quad(1\le i\le k).
    \]
    Consequently $z\neq x_{i}$ for every $i$, i.e.~$z\in F^{c}$.  Thus $B(y,\varepsilon)\subset F^{c}$, so every exterior point is interior to the complement; $F^{c}$ is open and $F$ is closed.

    An alternative argument is to note that each singleton $\{x_{i}\}$ is closed (apply the previous step with $k=1$) and that a finite union of closed sets remains closed:
    \[
        F\;=\;\bigcup_{i=1}^{k}\{x_{i}\}.\qedhere
    \]
\end{proof}

\begin{remark}
    \emph{Idea of the proof.}  For a point $y$ not in the finite set we compute its distances to each listed point.  The smallest of these distances is still positive; taking half of it as the radius gives a neighbourhood around $y$ that misses the entire finite set, showing the complement is open.  Equivalently, observe that singletons are closed and a finite union of closed sets is closed.
\end{remark}

\begin{exercise}[4.6]
    Show that in $\mathbb{R}^n$ no point $x$ with $\|x\|=1$ is an interior point of the closed unit ball $\overline{B(0,1)}$.
\end{exercise}

\begin{proof}
    Let $x\in\mathbb R^{n}$ satisfy $\|x\|=1$.  To show that $x$ is \emph{not} an interior point of $\overline{B(0,1)}$ we must prove that every open ball centred at $x$ contains points that lie \emph{outside} $\overline{B(0,1)}$.

    Fix an arbitrary radius $r>0$ and define
    \[
        y\;:=\;\bigl(1+\tfrac{r}{2}\bigr)\,x.
    \]
    Then
    \[
        \|y-x\|=\Bigl|\,1+\tfrac{r}{2}-1\Bigr|\,\|x\|=\frac{r}{2}<r,\qquad \text{but}\qquad \|y\|=1+\tfrac{r}{2}>1.
    \]
    Hence $y$ lies within the ball $B(x,r)$ yet satisfies $\|y\|>1$, so $y\notin\overline{B(0,1)}$.  Consequently $B(x,r)$ is \emph{not} contained in $\overline{B(0,1)}$.  Because $r>0$ was arbitrary, no open neighbourhood of $x$ sits inside the closed unit ball, and thus $x$ is not an interior point.
\end{proof}

\begin{remark}
    \emph{Idea of the proof.}  Any boundary point $x$ with $\|x\|=1$ can be pushed slightly outward along its own direction: scaling by $1+\varepsilon$ moves the point a distance roughly $\varepsilon$ while immediately leaving the unit ball.  No matter how small a radius we choose, such an outward perturbation fits inside the radius yet escapes the ball, so the original point cannot be interior.
\end{remark}

\end{document}
